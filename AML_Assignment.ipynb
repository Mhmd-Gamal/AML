{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRy6zWS0NE0Y"
      },
      "source": [
        "# Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "IxRsXylP-XU1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gX5R4a9GgESz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d20b96-e47d-444a-c5b3-50bcc0b52655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data_transaction.zip\n",
            "  inflating: data_transaction.csv    \n",
            "Archive:  data_identity.zip\n",
            "  inflating: data_identity.csv       \n"
          ]
        }
      ],
      "source": [
        "!unzip data_transaction.zip\n",
        "!unzip data_identity.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rufzddlXhQA1"
      },
      "outputs": [],
      "source": [
        "#data_trans = pd.read_csv(\"C:\\\\Users\\\\User\\\\Downloads\\\\IU\\\\AML\\\\Assignments\\\\A2\\ieee-fraud-detection\\data_transaction.csv\")\n",
        "#data_identity = pd.read_csv(\"C:\\\\Users\\\\User\\\\Downloads\\\\IU\\\\AML\\\\Assignments\\\\A2\\ieee-fraud-detection\\data_identity.csv\")\n",
        "data_trans = pd.read_csv(\"data_transaction.csv\")\n",
        "data_identity = pd.read_csv(\"data_identity.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfHPdvLpducc",
        "outputId": "ecad43c9-0f3d-409c-be62-42007e6ef273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data transaction shape (590540, 394)\n",
            "data identity shape (144233, 41)\n"
          ]
        }
      ],
      "source": [
        "print(\"data transaction shape\", data_trans.shape)\n",
        "print(\"data identity shape\", data_identity.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0VC5Xv7S5dw"
      },
      "source": [
        "#### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "RQKbMwzwhXQw",
        "outputId": "667b2800-3a02-43e1-c0b7-f6f1a09d800c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
              "0        2987004        0          86506          50.000         H   4497   \n",
              "1        2987008        0          86535          15.000         H   2803   \n",
              "2        2987010        0          86549          75.887         C  16496   \n",
              "3        2987011        0          86555          16.495         C   4461   \n",
              "4        2987016        0          86620          30.000         H   1790   \n",
              "\n",
              "   card2  card3       card4  card5  ...                id_31  id_32  \\\n",
              "0  514.0  150.0  mastercard  102.0  ...  samsung browser 6.2   32.0   \n",
              "1  100.0  150.0        visa  226.0  ...   mobile safari 11.0   32.0   \n",
              "2  352.0  117.0  mastercard  134.0  ...          chrome 62.0    NaN   \n",
              "3  375.0  185.0  mastercard  224.0  ...          chrome 62.0    NaN   \n",
              "4  555.0  150.0        visa  226.0  ...          chrome 62.0   24.0   \n",
              "\n",
              "       id_33           id_34  id_35 id_36 id_37  id_38  DeviceType  \\\n",
              "0  2220x1080  match_status:2      T     F     T      T      mobile   \n",
              "1   1334x750  match_status:1      T     F     F      T      mobile   \n",
              "2        NaN             NaN      F     F     T      T     desktop   \n",
              "3        NaN             NaN      F     F     T      T     desktop   \n",
              "4   1280x800  match_status:2      T     F     T      T     desktop   \n",
              "\n",
              "                      DeviceInfo  \n",
              "0  SAMSUNG SM-G892A Build/NRD90M  \n",
              "1                     iOS Device  \n",
              "2                        Windows  \n",
              "3                            NaN  \n",
              "4                          MacOS  \n",
              "\n",
              "[5 rows x 434 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eda0cdee-3cb3-493c-b3e3-127dcaebe731\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>...</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.000</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>...</td>\n",
              "      <td>samsung browser 6.2</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2220x1080</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987008</td>\n",
              "      <td>0</td>\n",
              "      <td>86535</td>\n",
              "      <td>15.000</td>\n",
              "      <td>H</td>\n",
              "      <td>2803</td>\n",
              "      <td>100.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>226.0</td>\n",
              "      <td>...</td>\n",
              "      <td>mobile safari 11.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1334x750</td>\n",
              "      <td>match_status:1</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "      <td>iOS Device</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987010</td>\n",
              "      <td>0</td>\n",
              "      <td>86549</td>\n",
              "      <td>75.887</td>\n",
              "      <td>C</td>\n",
              "      <td>16496</td>\n",
              "      <td>352.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>134.0</td>\n",
              "      <td>...</td>\n",
              "      <td>chrome 62.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>desktop</td>\n",
              "      <td>Windows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987011</td>\n",
              "      <td>0</td>\n",
              "      <td>86555</td>\n",
              "      <td>16.495</td>\n",
              "      <td>C</td>\n",
              "      <td>4461</td>\n",
              "      <td>375.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>224.0</td>\n",
              "      <td>...</td>\n",
              "      <td>chrome 62.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>desktop</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987016</td>\n",
              "      <td>0</td>\n",
              "      <td>86620</td>\n",
              "      <td>30.000</td>\n",
              "      <td>H</td>\n",
              "      <td>1790</td>\n",
              "      <td>555.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>226.0</td>\n",
              "      <td>...</td>\n",
              "      <td>chrome 62.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1280x800</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>desktop</td>\n",
              "      <td>MacOS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 434 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eda0cdee-3cb3-493c-b3e3-127dcaebe731')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eda0cdee-3cb3-493c-b3e3-127dcaebe731 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eda0cdee-3cb3-493c-b3e3-127dcaebe731');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#df = data_trans.merge(data_identity, how='left', left_index=True, right_index=True)\n",
        "# Merge the tables \n",
        "df = pd.merge(left=data_trans, right=data_identity, left_on='TransactionID', right_on='TransactionID')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del data_trans\n",
        "del data_identity"
      ],
      "metadata": {
        "id": "uyEzG77q0QX0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVC_TJsUiszx",
        "outputId": "46acbd3c-ef6f-4cc9-c5b1-d81de19f40bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144233, 434)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "x5SiRlF-gES2"
      },
      "outputs": [],
      "source": [
        "list_cat = list(df.select_dtypes('object').columns.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vQ5hK2cUgES3"
      },
      "outputs": [],
      "source": [
        "# Remove the categorical data\n",
        "df.drop(df[list_cat], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmgHtht9gES3",
        "outputId": "347b2047-8439-49a7-ad07-9918176ebdcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144233, 403)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NqFBSvjafLhM"
      },
      "outputs": [],
      "source": [
        "# Remove empty columns\n",
        "emp = [col for col in df.columns if df[col].isnull().values.all()]\n",
        "df.drop(df[emp], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I15lqxxJMuXc",
        "outputId": "5af1ef48-1281-428e-fa2d-673ec94afafb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144233, 390)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['isFraud'].to_numpy()\n",
        "df.drop('isFraud', axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "M_-5DGD49qEU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ODszN1kV_hu"
      },
      "source": [
        "#### Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Y3sApn8wdW0G",
        "outputId": "2ea960b7-082d-436c-f8c0-e7cf154659fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   TransactionID  TransactionDT  TransactionAmt  card1  card2  card3  card5  \\\n",
              "0        2987004          86506          50.000   4497  514.0  150.0  102.0   \n",
              "1        2987008          86535          15.000   2803  100.0  150.0  226.0   \n",
              "2        2987010          86549          75.887  16496  352.0  117.0  134.0   \n",
              "3        2987011          86555          16.495   4461  375.0  185.0  224.0   \n",
              "4        2987016          86620          30.000   1790  555.0  150.0  226.0   \n",
              "\n",
              "   addr1  addr2  dist2  ...  id_17  id_18  id_19  id_20  id_21  id_22  id_24  \\\n",
              "0  420.0   87.0    NaN  ...  166.0    NaN  542.0  144.0    NaN    NaN    NaN   \n",
              "1  337.0   87.0    NaN  ...  166.0    NaN  621.0  500.0    NaN    NaN    NaN   \n",
              "2    NaN    NaN    NaN  ...  121.0    NaN  410.0  142.0    NaN    NaN    NaN   \n",
              "3    NaN    NaN   30.0  ...  225.0    NaN  176.0  507.0    NaN    NaN    NaN   \n",
              "4  170.0   87.0    NaN  ...  166.0   15.0  529.0  575.0    NaN    NaN    NaN   \n",
              "\n",
              "   id_25  id_26  id_32  \n",
              "0    NaN    NaN   32.0  \n",
              "1    NaN    NaN   32.0  \n",
              "2    NaN    NaN    NaN  \n",
              "3    NaN    NaN    NaN  \n",
              "4    NaN    NaN   24.0  \n",
              "\n",
              "[5 rows x 389 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7785cfb1-3894-4797-9ae3-0f3e11ac0687\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist2</th>\n",
              "      <th>...</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987004</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.000</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>542.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987008</td>\n",
              "      <td>86535</td>\n",
              "      <td>15.000</td>\n",
              "      <td>2803</td>\n",
              "      <td>100.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>621.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987010</td>\n",
              "      <td>86549</td>\n",
              "      <td>75.887</td>\n",
              "      <td>16496</td>\n",
              "      <td>352.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>121.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>410.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987011</td>\n",
              "      <td>86555</td>\n",
              "      <td>16.495</td>\n",
              "      <td>4461</td>\n",
              "      <td>375.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>225.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>176.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987016</td>\n",
              "      <td>86620</td>\n",
              "      <td>30.000</td>\n",
              "      <td>1790</td>\n",
              "      <td>555.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>166.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>529.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 389 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7785cfb1-3894-4797-9ae3-0f3e11ac0687')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7785cfb1-3894-4797-9ae3-0f3e11ac0687 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7785cfb1-3894-4797-9ae3-0f3e11ac0687');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GhSCJWzmdHHk"
      },
      "outputs": [],
      "source": [
        "df_clear = df.notna().astype(\"int\").to_numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = df.fillna(0)"
      ],
      "metadata": {
        "id": "kGmm9IRj428N"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "mask = sc.fit_transform(mask.to_numpy())"
      ],
      "metadata": {
        "id": "nZVTaTqY6fT3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data = np.hstack([mask, df_clear])"
      ],
      "metadata": {
        "id": "Ot79D8Yp7kk3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKUybr6U7knw",
        "outputId": "09bb00d0-820d-4f02-e4e1-dc06d41ebb89"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144233, 778)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8Gr80_ZpWMoS"
      },
      "outputs": [],
      "source": [
        "#Splitting \n",
        "X_train, X_test, y_train, y_test = train_test_split( full_data, y, test_size=0.2, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB6K0Xym-_ul",
        "outputId": "44b25c22-f79b-4141-da3c-dedd5c2d988b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(115386, 778)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mn1sw4L-zq-F"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wThkLZDQLwEi"
      },
      "source": [
        "#### Define the models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Undercomplete AE"
      ],
      "metadata": {
        "id": "ipNOkla4mWSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "D93zMaA3LW-g"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1pxUNj0TgES6"
      },
      "outputs": [],
      "source": [
        "## Undercomplete\n",
        "\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self, input_size, latent_dim):\n",
        "      super(autoencoder, self).__init__()\n",
        "      # Step 1 : Define the encoder \n",
        "      # Step 2 : Define the decoder\n",
        "      # Step 3 : Initialize the weights (optional)\n",
        "      self.encoder = nn.Sequential(\n",
        "          nn.Linear(input_size, input_size//2),\n",
        "          nn.ReLU(True),\n",
        "          nn.Linear(input_size//2, input_size//3),\n",
        "          nn.Linear(input_size//3, input_size//4),\n",
        "          nn.Tanh(),\n",
        "          nn.Linear(input_size//4, latent_dim)\n",
        "      )\n",
        "      self.decoder = nn.Sequential(\n",
        "          nn.Linear(latent_dim, input_size//4),\n",
        "          nn.ReLU(True),\n",
        "          nn.Linear(input_size//4, input_size//3),\n",
        "          nn.Tanh(),\n",
        "          nn.Linear(input_size//3, input_size//2)\n",
        "      )\n",
        "      self.encoder.apply(self.__init_weights)\n",
        "      self.decoder.apply(self.__init_weights)\n",
        "        \n",
        "    def forward(self, x):\n",
        "      # Step 1: Pass the input through encoder to get latent representation\n",
        "      # Step 2: Take latent representation and pass through decoder\n",
        "      x = self.encoder(x)\n",
        "      x = self.decoder(x)\n",
        "      return x\n",
        "        \n",
        "    \n",
        "    def encode(self,input):\n",
        "      #Step 1: Pass the input through the encoder to get latent representation\n",
        "      return self.encoder(input)\n",
        "    \n",
        "    def decode(self, input):\n",
        "      return self.decoder(input)\n",
        "    \n",
        "    def __init_weights(self,m):\n",
        "      #Init the weights (optional)\n",
        "      if type(m) == nn.Linear:\n",
        "          torch.nn.init.xavier_uniform_(m.weight)\n",
        "          m.bias.data.fill_(0.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vFqT_zbD6wr",
        "outputId": "dc0f7d51-fe3d-4e99-f19a-27ab37fd1687"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144233, 778)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BHBtiF5fgES7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fae3dfc-6619-473f-c2dc-69f70141de10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autoencoder(\n",
            "  (encoder): Sequential(\n",
            "    (0): Linear(in_features=778, out_features=389, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=389, out_features=259, bias=True)\n",
            "    (3): Linear(in_features=259, out_features=194, bias=True)\n",
            "    (4): Tanh()\n",
            "    (5): Linear(in_features=194, out_features=50, bias=True)\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=194, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Linear(in_features=194, out_features=259, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=259, out_features=389, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define training parameters\n",
        "\n",
        "min_lose = 10\n",
        "batchSize = 512\n",
        "learning_rate = 0.001\n",
        "num_epochs = 50\n",
        "latent_size = 50\n",
        "###sample = torch.randn((batchSize,1,64))\n",
        "AE = autoencoder(full_data.shape[1] , latent_size).to(device)\n",
        "print(AE)\n",
        "# print(summary(AE,input_size=(1, 64)))\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(AE.parameters(),lr=learning_rate)\n",
        "\n",
        "# create DataLoaders\n",
        "dataLoader_train = DataLoader(TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train)), batch_size=batchSize, shuffle=True)\n",
        "dataLoader_test = DataLoader(TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test)), batch_size=batchSize, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FFWMqePLgES7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664d9326-93bb-4d83-a765-2131e00dd56a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/50], train_loss:0.4612\n",
            "epoch [2/50], train_loss:0.3021\n",
            "epoch [3/50], train_loss:0.2599\n",
            "epoch [4/50], train_loss:0.2374\n",
            "epoch [5/50], train_loss:0.2232\n",
            "epoch [6/50], train_loss:0.2105\n",
            "epoch [7/50], train_loss:0.2099\n",
            "epoch [8/50], train_loss:0.2030\n",
            "epoch [9/50], train_loss:0.1968\n",
            "epoch [10/50], train_loss:0.1956\n",
            "epoch [11/50], train_loss:0.1939\n",
            "epoch [12/50], train_loss:0.1853\n",
            "epoch [13/50], train_loss:0.1825\n",
            "epoch [14/50], train_loss:0.1835\n",
            "epoch [15/50], train_loss:0.1780\n",
            "epoch [16/50], train_loss:0.1767\n",
            "epoch [17/50], train_loss:0.1765\n",
            "epoch [18/50], train_loss:0.1799\n",
            "epoch [19/50], train_loss:0.1729\n",
            "epoch [20/50], train_loss:0.1725\n",
            "epoch [21/50], train_loss:0.1780\n",
            "epoch [22/50], train_loss:0.1693\n",
            "epoch [23/50], train_loss:0.3688\n",
            "epoch [24/50], train_loss:0.2939\n",
            "epoch [25/50], train_loss:0.2664\n",
            "epoch [26/50], train_loss:0.2527\n",
            "epoch [27/50], train_loss:0.2381\n",
            "epoch [28/50], train_loss:0.2294\n",
            "epoch [29/50], train_loss:0.2248\n",
            "epoch [30/50], train_loss:0.2168\n",
            "epoch [31/50], train_loss:0.2122\n",
            "epoch [32/50], train_loss:0.2149\n",
            "epoch [33/50], train_loss:0.2066\n",
            "epoch [34/50], train_loss:0.2034\n",
            "epoch [35/50], train_loss:0.2077\n",
            "epoch [36/50], train_loss:0.1991\n",
            "epoch [37/50], train_loss:0.1974\n",
            "epoch [38/50], train_loss:0.2080\n",
            "epoch [39/50], train_loss:0.1992\n",
            "epoch [40/50], train_loss:0.2018\n",
            "epoch [41/50], train_loss:0.1911\n",
            "epoch [42/50], train_loss:0.1944\n",
            "epoch [43/50], train_loss:0.1951\n",
            "epoch [44/50], train_loss:0.1908\n",
            "epoch [45/50], train_loss:0.1922\n",
            "epoch [46/50], train_loss:0.1961\n",
            "epoch [47/50], train_loss:0.1948\n",
            "epoch [48/50], train_loss:0.1903\n",
            "epoch [49/50], train_loss:0.1862\n",
            "epoch [50/50], train_loss:0.1904\n"
          ]
        }
      ],
      "source": [
        "## Trainning the Autoencoder\n",
        "ind = full_data.shape[1]//2\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss = 0.0\n",
        "  for X in dataLoader_train:\n",
        "    X = X[0].to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward\n",
        "    output = AE(X)\n",
        "    loss = criterion(output * X[:, ind:], X[:, :ind])\n",
        "    #print(output.dtype)\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  # log\n",
        "\n",
        "  print('epoch [{}/{}], train_loss:{:.4f}'.format(epoch + 1, num_epochs, epoch_loss / len(dataLoader_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dKcuwGy6gES7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dabb4ad-bf41-4858-b729-9e3764897b2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/50], test_loss:0.2050\n",
            "epoch [2/50], test_loss:0.2048\n",
            "epoch [3/50], test_loss:0.2081\n",
            "epoch [4/50], test_loss:0.2049\n",
            "epoch [5/50], test_loss:0.2053\n",
            "epoch [6/50], test_loss:0.2048\n",
            "epoch [7/50], test_loss:0.2046\n",
            "epoch [8/50], test_loss:0.2056\n",
            "epoch [9/50], test_loss:0.2050\n",
            "epoch [10/50], test_loss:0.2051\n",
            "epoch [11/50], test_loss:0.2048\n",
            "epoch [12/50], test_loss:0.2052\n",
            "epoch [13/50], test_loss:0.2050\n",
            "epoch [14/50], test_loss:0.2050\n",
            "epoch [15/50], test_loss:0.2060\n",
            "epoch [16/50], test_loss:0.2051\n",
            "epoch [17/50], test_loss:0.2324\n",
            "epoch [18/50], test_loss:0.2059\n",
            "epoch [19/50], test_loss:0.2049\n",
            "epoch [20/50], test_loss:0.2049\n",
            "epoch [21/50], test_loss:0.2049\n",
            "epoch [22/50], test_loss:0.2051\n",
            "epoch [23/50], test_loss:0.2047\n",
            "epoch [24/50], test_loss:0.2052\n",
            "epoch [25/50], test_loss:0.2051\n",
            "epoch [26/50], test_loss:0.2049\n",
            "epoch [27/50], test_loss:0.2049\n",
            "epoch [28/50], test_loss:0.2275\n",
            "epoch [29/50], test_loss:0.2049\n",
            "epoch [30/50], test_loss:0.2050\n",
            "epoch [31/50], test_loss:0.2049\n",
            "epoch [32/50], test_loss:0.2054\n",
            "epoch [33/50], test_loss:0.2051\n",
            "epoch [34/50], test_loss:0.2050\n",
            "epoch [35/50], test_loss:0.2050\n",
            "epoch [36/50], test_loss:0.2050\n",
            "epoch [37/50], test_loss:0.2047\n",
            "epoch [38/50], test_loss:0.2048\n",
            "epoch [39/50], test_loss:0.2052\n",
            "epoch [40/50], test_loss:0.2058\n",
            "epoch [41/50], test_loss:0.2050\n",
            "epoch [42/50], test_loss:0.2048\n",
            "epoch [43/50], test_loss:0.2060\n",
            "epoch [44/50], test_loss:0.2047\n",
            "epoch [45/50], test_loss:0.2051\n",
            "epoch [46/50], test_loss:0.2047\n",
            "epoch [47/50], test_loss:0.2052\n",
            "epoch [48/50], test_loss:0.2048\n",
            "epoch [49/50], test_loss:0.2048\n",
            "epoch [50/50], test_loss:0.2050\n"
          ]
        }
      ],
      "source": [
        "# Test \n",
        "min_undercomplete_loss = 10\n",
        "top = AE.state_dict()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  with torch.no_grad():\n",
        "    loss = 0\n",
        "    for X in dataLoader_test:\n",
        "      X = X[0].to(device)\n",
        "      \n",
        "      output = AE(X)\n",
        "      loss += criterion(output * X[:, ind:], X[:, :ind]).item()\n",
        "    res = loss / len(dataLoader_test)\n",
        "    if res < min_undercomplete_loss:\n",
        "        min_undercomplete_loss = res\n",
        "        top = AE.state_dict()\n",
        "    else: \n",
        "        AE.load_state_dict(top)\n",
        "    print('epoch [{}/{}], test_loss:{:.4f}'.format(epoch + 1, num_epochs, res ))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Regularized AE "
      ],
      "metadata": {
        "id": "dO4NkFdnmNKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sparse autoencoder**"
      ],
      "metadata": {
        "id": "_y_pVB8mxAFs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "igWRw3JqgES8"
      },
      "outputs": [],
      "source": [
        "def regLoss(data):\n",
        "    AE_children = list(AE.children())\n",
        "    l = 0\n",
        "    v = data\n",
        "    for x in range(len(AE_children)):\n",
        "        v = F.relu((AE_children[x](v)))\n",
        "        l += torch.mean(torch.abs(v))\n",
        "    return l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WDTj3ryXgES8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452e9168-5fdb-4e4d-a7d3-935991f8461a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/50], train_loss:0.3662\n",
            "epoch [2/50], train_loss:0.2370\n",
            "epoch [3/50], train_loss:0.2210\n",
            "epoch [4/50], train_loss:0.2218\n",
            "epoch [5/50], train_loss:0.2099\n",
            "epoch [6/50], train_loss:0.2064\n",
            "epoch [7/50], train_loss:0.2082\n",
            "epoch [8/50], train_loss:0.1993\n",
            "epoch [9/50], train_loss:0.1966\n",
            "epoch [10/50], train_loss:0.1938\n",
            "epoch [11/50], train_loss:0.1977\n",
            "epoch [12/50], train_loss:0.2025\n",
            "epoch [13/50], train_loss:0.1966\n",
            "epoch [14/50], train_loss:0.1903\n",
            "epoch [15/50], train_loss:0.1922\n",
            "epoch [16/50], train_loss:0.1930\n",
            "epoch [17/50], train_loss:0.1870\n",
            "epoch [18/50], train_loss:0.1913\n",
            "epoch [19/50], train_loss:0.1999\n",
            "epoch [20/50], train_loss:0.2017\n",
            "epoch [21/50], train_loss:0.1914\n",
            "epoch [22/50], train_loss:0.1864\n",
            "epoch [23/50], train_loss:0.1866\n",
            "epoch [24/50], train_loss:0.1850\n",
            "epoch [25/50], train_loss:0.1837\n",
            "epoch [26/50], train_loss:0.1811\n",
            "epoch [27/50], train_loss:0.1803\n",
            "epoch [28/50], train_loss:0.1824\n",
            "epoch [29/50], train_loss:0.1944\n",
            "epoch [30/50], train_loss:0.1870\n",
            "epoch [31/50], train_loss:0.1805\n",
            "epoch [32/50], train_loss:0.1811\n",
            "epoch [33/50], train_loss:0.1798\n",
            "epoch [34/50], train_loss:0.1806\n",
            "epoch [35/50], train_loss:0.1780\n",
            "epoch [36/50], train_loss:0.1920\n",
            "epoch [37/50], train_loss:0.1867\n",
            "epoch [38/50], train_loss:0.1792\n",
            "epoch [39/50], train_loss:0.1790\n",
            "epoch [40/50], train_loss:0.1727\n",
            "epoch [41/50], train_loss:0.1692\n",
            "epoch [42/50], train_loss:0.1810\n",
            "epoch [43/50], train_loss:0.1798\n",
            "epoch [44/50], train_loss:0.1763\n",
            "epoch [45/50], train_loss:0.1724\n",
            "epoch [46/50], train_loss:0.1759\n",
            "epoch [47/50], train_loss:0.1807\n",
            "epoch [48/50], train_loss:0.1899\n",
            "epoch [49/50], train_loss:0.1816\n",
            "epoch [50/50], train_loss:0.1764\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss = 0.0\n",
        "  for X in dataLoader_train:\n",
        "    X = X[0].to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward\n",
        "    output = AE(X)\n",
        "    loss = criterion(output * X[:, ind:], X[:, :ind])\n",
        "    l1_loss = regLoss(X)\n",
        "    loss = loss +  l1_loss\n",
        "    #print(output.dtype)\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  # log\n",
        "  print('epoch [{}/{}], train_loss:{:.4f}'.format(epoch + 1, num_epochs, epoch_loss / len(dataLoader_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ekwImrhdgES9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5418391f-d684-43da-d76e-170e7eea82fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/50], test_loss:0.2000\n",
            "epoch [2/50], test_loss:0.1999\n",
            "epoch [3/50], test_loss:0.1997\n",
            "epoch [4/50], test_loss:0.1999\n",
            "epoch [5/50], test_loss:0.1999\n",
            "epoch [6/50], test_loss:0.2027\n",
            "epoch [7/50], test_loss:0.1998\n",
            "epoch [8/50], test_loss:0.1997\n",
            "epoch [9/50], test_loss:0.2000\n",
            "epoch [10/50], test_loss:0.1999\n",
            "epoch [11/50], test_loss:0.1999\n",
            "epoch [12/50], test_loss:0.2003\n",
            "epoch [13/50], test_loss:0.1998\n",
            "epoch [14/50], test_loss:0.2003\n",
            "epoch [15/50], test_loss:0.1999\n",
            "epoch [16/50], test_loss:0.1998\n",
            "epoch [17/50], test_loss:0.2000\n",
            "epoch [18/50], test_loss:0.1999\n",
            "epoch [19/50], test_loss:0.2008\n",
            "epoch [20/50], test_loss:0.1997\n",
            "epoch [21/50], test_loss:0.1998\n",
            "epoch [22/50], test_loss:0.1997\n",
            "epoch [23/50], test_loss:0.2008\n",
            "epoch [24/50], test_loss:0.1997\n",
            "epoch [25/50], test_loss:0.2009\n",
            "epoch [26/50], test_loss:0.1998\n",
            "epoch [27/50], test_loss:0.1998\n",
            "epoch [28/50], test_loss:0.1999\n",
            "epoch [29/50], test_loss:0.1998\n",
            "epoch [30/50], test_loss:0.2010\n",
            "epoch [31/50], test_loss:0.1998\n",
            "epoch [32/50], test_loss:0.1998\n",
            "epoch [33/50], test_loss:0.1998\n",
            "epoch [34/50], test_loss:0.1998\n",
            "epoch [35/50], test_loss:0.1999\n",
            "epoch [36/50], test_loss:0.1999\n",
            "epoch [37/50], test_loss:0.2000\n",
            "epoch [38/50], test_loss:0.2009\n",
            "epoch [39/50], test_loss:0.1998\n",
            "epoch [40/50], test_loss:0.2003\n",
            "epoch [41/50], test_loss:0.1996\n",
            "epoch [42/50], test_loss:0.1999\n",
            "epoch [43/50], test_loss:0.1996\n",
            "epoch [44/50], test_loss:0.1999\n",
            "epoch [45/50], test_loss:0.1997\n",
            "epoch [46/50], test_loss:0.1998\n",
            "epoch [47/50], test_loss:0.1998\n",
            "epoch [48/50], test_loss:0.1997\n",
            "epoch [49/50], test_loss:0.1999\n",
            "epoch [50/50], test_loss:0.2010\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "min_reg_ae = 10\n",
        "for epoch in range(num_epochs):\n",
        "  with torch.no_grad():\n",
        "    loss = 0\n",
        "    for X in dataLoader_test:\n",
        "      X = X[0].to(device)\n",
        "      \n",
        "      output = AE(X)\n",
        "      loss += criterion(output * X[:, ind:], X[:, :ind]).item()\n",
        "    \n",
        "    print('epoch [{}/{}], test_loss:{:.4f}'.format(epoch + 1, num_epochs, loss / len(dataLoader_test)))\n",
        "    if (loss / len(dataLoader_test)) < min_reg_ae:\n",
        "      min_reg_ae = (loss / len(dataLoader_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Variational AE "
      ],
      "metadata": {
        "id": "fw7_yeB4yZ8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4MfpfuIKgES_"
      },
      "outputs": [],
      "source": [
        "# VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim= full_data.shape[1], h_dim= 389, z_dim=5):\n",
        "        super(VAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, h_dim)\n",
        "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
        "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
        "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
        "        self.fc5 = nn.Linear(h_dim, input_dim//2)\n",
        "        \n",
        "    def encode(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        return self.fc2(h), self.fc3(h)\n",
        "    \n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(log_var/2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = F.relu(self.fc4(z))\n",
        "        return self.fc5(h)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encode(x)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        x_reconst = self.decode(z)\n",
        "        return x_reconst, mu, log_var\n",
        "\n",
        "model = VAE().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCJKkrPT3k2K",
        "outputId": "2c693135-9fac-4866-9c15-0d8343a2116c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE(\n",
            "  (fc1): Linear(in_features=778, out_features=389, bias=True)\n",
            "  (fc2): Linear(in_features=389, out_features=5, bias=True)\n",
            "  (fc3): Linear(in_features=389, out_features=5, bias=True)\n",
            "  (fc4): Linear(in_features=5, out_features=389, bias=True)\n",
            "  (fc5): Linear(in_features=389, out_features=389, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "TRl4BpvQgES_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7510e83a-030b-4777-8553-72e73dce6504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/50], train_loss:32.5471\n",
            "epoch [2/50], train_loss:25.9521\n",
            "epoch [3/50], train_loss:32.1549\n",
            "epoch [4/50], train_loss:32.6807\n",
            "epoch [5/50], train_loss:20.9882\n",
            "epoch [6/50], train_loss:23.0161\n",
            "epoch [7/50], train_loss:28.7523\n",
            "epoch [8/50], train_loss:31.4485\n",
            "epoch [9/50], train_loss:29.0393\n",
            "epoch [10/50], train_loss:19.8426\n",
            "epoch [11/50], train_loss:35.7764\n",
            "epoch [12/50], train_loss:25.0710\n",
            "epoch [13/50], train_loss:29.5866\n",
            "epoch [14/50], train_loss:34.3789\n",
            "epoch [15/50], train_loss:35.8678\n",
            "epoch [16/50], train_loss:203.2830\n",
            "epoch [17/50], train_loss:27.0489\n",
            "epoch [18/50], train_loss:28.3591\n",
            "epoch [19/50], train_loss:24.0067\n",
            "epoch [20/50], train_loss:22.2269\n",
            "epoch [21/50], train_loss:24.6657\n",
            "epoch [22/50], train_loss:31.5977\n",
            "epoch [23/50], train_loss:34.3280\n",
            "epoch [24/50], train_loss:27.1938\n",
            "epoch [25/50], train_loss:29.4029\n",
            "epoch [26/50], train_loss:25.3846\n",
            "epoch [27/50], train_loss:24.0688\n",
            "epoch [28/50], train_loss:23.4872\n",
            "epoch [29/50], train_loss:26.7886\n",
            "epoch [30/50], train_loss:27.1361\n",
            "epoch [31/50], train_loss:30.1381\n",
            "epoch [32/50], train_loss:28.9193\n",
            "epoch [33/50], train_loss:23.7328\n",
            "epoch [34/50], train_loss:32.2003\n",
            "epoch [35/50], train_loss:39.0054\n",
            "epoch [36/50], train_loss:32.1607\n",
            "epoch [37/50], train_loss:28.6720\n",
            "epoch [38/50], train_loss:36.0067\n",
            "epoch [39/50], train_loss:33.5951\n",
            "epoch [40/50], train_loss:23.8801\n",
            "epoch [41/50], train_loss:24.8588\n",
            "epoch [42/50], train_loss:21.9408\n",
            "epoch [43/50], train_loss:32.6010\n",
            "epoch [44/50], train_loss:30.9768\n",
            "epoch [45/50], train_loss:25.2515\n",
            "epoch [46/50], train_loss:30.1901\n",
            "epoch [47/50], train_loss:29.1237\n",
            "epoch [48/50], train_loss:27.7482\n",
            "epoch [49/50], train_loss:29.9767\n",
            "epoch [50/50], train_loss:32.8907\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss = 0.0\n",
        "  for X in dataLoader_train:\n",
        "    X = X[0].to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward\n",
        "    x_reconst, mu, log_var = model(X)\n",
        "    loss = criterion(x_reconst*X[:, ind:], X[:, :ind])\n",
        "    kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    loss += kl_div\n",
        "\n",
        "    #print(output.dtype)\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  # log\n",
        "  print('epoch [{}/{}], train_loss:{:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "97ER0q5EgETA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be2b357-323c-4627-d0fe-564ddfd81f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/50], test_loss:0.9592\n",
            "epoch [2/50], test_loss:0.9570\n",
            "epoch [3/50], test_loss:0.9597\n",
            "epoch [4/50], test_loss:0.9555\n",
            "epoch [5/50], test_loss:0.9567\n",
            "epoch [6/50], test_loss:0.9550\n",
            "epoch [7/50], test_loss:0.9544\n",
            "epoch [8/50], test_loss:0.9539\n",
            "epoch [9/50], test_loss:0.9578\n",
            "epoch [10/50], test_loss:0.9562\n",
            "epoch [11/50], test_loss:0.9573\n",
            "epoch [12/50], test_loss:0.9577\n",
            "epoch [13/50], test_loss:0.9600\n",
            "epoch [14/50], test_loss:0.9626\n",
            "epoch [15/50], test_loss:0.9562\n",
            "epoch [16/50], test_loss:0.9563\n",
            "epoch [17/50], test_loss:0.9626\n",
            "epoch [18/50], test_loss:0.9564\n",
            "epoch [19/50], test_loss:0.9607\n",
            "epoch [20/50], test_loss:0.9568\n",
            "epoch [21/50], test_loss:0.9570\n",
            "epoch [22/50], test_loss:0.9605\n",
            "epoch [23/50], test_loss:0.9711\n",
            "epoch [24/50], test_loss:0.9562\n",
            "epoch [25/50], test_loss:0.9563\n",
            "epoch [26/50], test_loss:0.9587\n",
            "epoch [27/50], test_loss:0.9573\n",
            "epoch [28/50], test_loss:0.9547\n",
            "epoch [29/50], test_loss:0.9557\n",
            "epoch [30/50], test_loss:0.9561\n",
            "epoch [31/50], test_loss:0.9606\n",
            "epoch [32/50], test_loss:0.9546\n",
            "epoch [33/50], test_loss:0.9565\n",
            "epoch [34/50], test_loss:0.9533\n",
            "epoch [35/50], test_loss:0.9575\n",
            "epoch [36/50], test_loss:0.9587\n",
            "epoch [37/50], test_loss:0.9566\n",
            "epoch [38/50], test_loss:0.9570\n",
            "epoch [39/50], test_loss:0.9670\n",
            "epoch [40/50], test_loss:0.9577\n",
            "epoch [41/50], test_loss:0.9583\n",
            "epoch [42/50], test_loss:0.9618\n",
            "epoch [43/50], test_loss:0.9578\n",
            "epoch [44/50], test_loss:0.9619\n",
            "epoch [45/50], test_loss:0.9562\n",
            "epoch [46/50], test_loss:0.9589\n",
            "epoch [47/50], test_loss:0.9590\n",
            "epoch [48/50], test_loss:0.9559\n",
            "epoch [49/50], test_loss:0.9573\n",
            "epoch [50/50], test_loss:0.9658\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "min_variational_ae = 10\n",
        "for epoch in range(num_epochs):\n",
        "  with torch.no_grad():\n",
        "    loss = 0\n",
        "    for X in dataLoader_test:\n",
        "      X = X[0].to(device)\n",
        "      \n",
        "      x_reconst, mu, log_var = model(X)\n",
        "      loss += criterion(x_reconst * X[:, ind:], X[:, :ind]).item()\n",
        "    \n",
        "    print('epoch [{}/{}], test_loss:{:.4f}'.format(epoch + 1, num_epochs, loss / len(dataLoader_test)))\n",
        "    if (loss / len(dataLoader_test)) < min_variational_ae:\n",
        "      min_variational_ae = (loss / len(dataLoader_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perfomence of autoencoder"
      ],
      "metadata": {
        "id": "L5dKtWVcE6X1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "HqfbYVzWgETA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c9219b-32f8-495d-8f27-6f1de539265c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Undercomplete AE >> Best loss  :: 0.2046424273336143\n",
            "Regularized  AE >> Best loss  :: 0.19962961971759796\n",
            "Variational AE >> Best loss  :: 0.9533320173882601\n"
          ]
        }
      ],
      "source": [
        "print(\"Undercomplete AE >> Best loss  ::\", min_undercomplete_loss)\n",
        "print(\"Regularized  AE >> Best loss  ::\", min_reg_ae)\n",
        "print(\"Variational AE >> Best loss  ::\", min_variational_ae)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Compare with statistical approaches"
      ],
      "metadata": {
        "id": "qs3XWqqTMlDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = autoencoder(full_data.shape[1] , latent_size).to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xqCho8H9HbA",
        "outputId": "7045b953-9693-4881-a571-800986572a5d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "autoencoder(\n",
              "  (encoder): Sequential(\n",
              "    (0): Linear(in_features=778, out_features=389, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=389, out_features=259, bias=True)\n",
              "    (3): Linear(in_features=259, out_features=194, bias=True)\n",
              "    (4): Tanh()\n",
              "    (5): Linear(in_features=194, out_features=50, bias=True)\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): Linear(in_features=50, out_features=194, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=194, out_features=259, bias=True)\n",
              "    (3): Tanh()\n",
              "    (4): Linear(in_features=259, out_features=389, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_data(data, model):\n",
        "  train,target =[],[]\n",
        "  for x, y in dataLoader_train:\n",
        "      x = x.to(device)\n",
        "      train.append(model(x).cpu().detach().numpy())\n",
        "      target.append(y.cpu().detach().numpy())\n",
        "  train = np.concatenate(train,  axis=0)\n",
        "  target = np.concatenate(target,  axis=0)\n",
        "  return train, target\n",
        "\n",
        "train_x, train_y = create_data(dataLoader_train, model )\n",
        "test_x, test_y = create_data(dataLoader_test, model )"
      ],
      "metadata": {
        "id": "l-NT2BUC3zdp"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(random_state=0).fit(train_x, train_y)\n",
        "pred = clf.predict(test_x)\n",
        "print(classification_report(test_y, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1cIsOQZ-0C2",
        "outputId": "88511e1b-edb1-4d59-e46d-5a1c96bf720b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.99      0.97    106268\n",
            "         1.0       0.80      0.33      0.46      9118\n",
            "\n",
            "    accuracy                           0.94    115386\n",
            "   macro avg       0.87      0.66      0.72    115386\n",
            "weighted avg       0.93      0.94      0.93    115386\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "GJ-7AT_tgETA"
      },
      "outputs": [],
      "source": [
        "# Imputing the data with mean \n",
        "\n",
        "def create_data_mask(data, model, indicator):\n",
        "  train,target, mask =[],[], []\n",
        "  for x, y in dataLoader_train:\n",
        "      x = x.cpu().detach().numpy()\n",
        "      train.append(x[:, :indicator])\n",
        "      mask.append(x[:, indicator:])\n",
        "      target.append(y.cpu().detach().numpy())\n",
        "  train = np.concatenate(train,  axis=0)\n",
        "  mask = np.concatenate(mask,  axis=0)\n",
        "  target = np.concatenate(target,  axis=0)\n",
        "  train = np.where(mask < 1, np.ma.array(train, mask=(mask < 1)).mean(axis=0), train)\n",
        "  return train, target\n",
        "\n",
        "train_x, train_y = create_data_mask(dataLoader_train, model ,ind)\n",
        "test_x, test_y = create_data_mask(dataLoader_test, model ,ind)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Wp4bXk9rgETA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0921c09-7d74-423a-d519-7762a5c98e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.99      0.97    106268\n",
            "         1.0       0.85      0.45      0.59      9118\n",
            "\n",
            "    accuracy                           0.95    115386\n",
            "   macro avg       0.90      0.72      0.78    115386\n",
            "weighted avg       0.95      0.95      0.94    115386\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = LogisticRegression(random_state=0).fit(train_x, train_y)\n",
        "pred = clf.predict(test_x)\n",
        "print(classification_report(test_y, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA Vs LDA"
      ],
      "metadata": {
        "id": "r3JekAd6JJ4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PCA"
      ],
      "metadata": {
        "id": "rMXk2mM5NttN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "62E_tWHYgETA"
      },
      "outputs": [],
      "source": [
        "xTrain, yTrain = create_data(dataLoader_train, model )\n",
        "xTest, yTest = create_data(dataLoader_test, model )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "3c94ldExgETA"
      },
      "outputs": [],
      "source": [
        "# survice function for Explained variance ratio plotting\n",
        "def plot_explained_variance(X):\n",
        "    #Calculating Eigenvecors and eigenvalues of Covariance matrix\n",
        "    mean_vec = np.mean(X, axis=0)\n",
        "    cov_mat = np.cov(X.T)\n",
        "    eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
        "    # Create a list of (eigenvalue, eigenvector) tuples\n",
        "    eig_pairs = [ (np.abs(eig_vals[i]),eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
        "\n",
        "    # Sort from high to low\n",
        "    eig_pairs.sort(key = lambda x: x[0], reverse= True)\n",
        "\n",
        "    # Calculation of Explained Variance from the eigenvalues\n",
        "    tot = sum(eig_vals)\n",
        "    print(tot)\n",
        "    var_exp = [(i/tot)*100 for i in sorted(eig_vals, reverse=True)] # Individual explained variance\n",
        "    print(var_exp)\n",
        "    cum_var_exp = np.cumsum(var_exp) # Cumulative explained variance\n",
        "    print(cum_var_exp)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(range(len(var_exp)), var_exp, alpha=0.3333, align='center', label='individual explained variance', color = 'g')\n",
        "    plt.step(range(len(cum_var_exp)), cum_var_exp, where='mid',label='cumulative explained variance')\n",
        "    plt.ylabel('Explained variance ratio')\n",
        "    plt.xlabel('Principal components')\n",
        "    plt.legend(loc='best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "mj0B4ubogETA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09d46dd9-1090-4f49-db17-ff34988c75e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(389.00337135865396+0j)\n",
            "[(24.94256840181095+0j), (9.651696268902132+0j), (7.5725386821467735+0j), (5.539460220077744+0j), (4.800225113920192+0j), (4.596720332111096+0j), (3.7868429404049024+0j), (3.3115658547559144+0j), (2.698839067367609+0j), (2.4078612495220386+0j), (2.0673285108727306+0j), (1.7067288852213067+0j), (1.6246544463322208+0j), (1.5814380329514557+0j), (1.541123549429841+0j), (1.4197102693185546+0j), (1.3464014003746392+0j), (1.0454948609347108+0j), (0.9147404862009205+0j), (0.8835846843080926+0j), (0.8217770557014467+0j), (0.7845909034768931+0j), (0.7353263629302932+0j), (0.6991873112781657+0j), (0.6598276609485711+0j), (0.6455064949947948+0j), (0.5725426210073029+0j), (0.5633881991808832+0j), (0.5236118928360486+0j), (0.4705751137168971+0j), (0.42769999420897464+0j), (0.41930682578336853+0j), (0.40239296325510304+0j), (0.37531779383000186+0j), (0.34594510429220676+0j), (0.3162760094110595+0j), (0.3126555089166377+0j), (0.3071885163257777+0j), (0.2956605782815557+0j), (0.2720541887725258+0j), (0.26460481241641254+0j), (0.2603748828427239+0j), (0.25376009136326805+0j), (0.23357824154348214+0j), (0.2033526228593741+0j), (0.19976774783977622+0j), (0.1894300868826225+0j), (0.17589314609686543+0j), (0.1740609264007011+0j), (0.17023387530891446+0j), (0.16130768023111644+0j), (0.15322784239134268+0j), (0.14977809573223005+0j), (0.1454772277166282+0j), (0.1374089754274784+0j), (0.1311259346570863+0j), (0.12560855438262453+0j), (0.12137066667219183+0j), (0.1182927645507673+0j), (0.11302504098355387+0j), (0.10479576854317914+0j), (0.10145888574702837+0j), (0.09761000186131179+0j), (0.09492968576173877+0j), (0.08859588263074755+0j), (0.08606276372658249+0j), (0.08370871578306477+0j), (0.08092875588120205+0j), (0.07861138164388617+0j), (0.07581938223896499+0j), (0.07444353774243616+0j), (0.07357750508515935+0j), (0.06998119753289367+0j), (0.06569082255034626+0j), (0.06483354936408844+0j), (0.06282033414109744+0j), (0.0609156463164163+0j), (0.056912906210808745+0j), (0.05549768142155678+0j), (0.05349156610875938+0j), (0.05248174094654841+0j), (0.051091480554230885+0j), (0.04883636290904184+0j), (0.047124178706989664+0j), (0.0466391132975893+0j), (0.0454405867858411+0j), (0.04149109273900254+0j), (0.040696339101326875+0j), (0.04030673228026106+0j), (0.03970129334044987+0j), (0.03896591288718343+0j), (0.03689366967676518+0j), (0.03649532385773103+0j), (0.035093993257947695+0j), (0.03464587384213598+0j), (0.03315698794527334+0j), (0.03114478178992834+0j), (0.030889037452098672+0j), (0.030028508134737873+0j), (0.028384393759713702+0j), (0.027823859034028234+0j), (0.0262453834675096+0j), (0.025616149640672024+0j), (0.024615564357375323+0j), (0.0242209059781082+0j), (0.023303315561713178+0j), (0.02275208989399726+0j), (0.02169847377597+0j), (0.021287454437843606+0j), (0.02039533563559639+0j), (0.019970849344445943+0j), (0.019584040607487238+0j), (0.018867933266822116+0j), (0.018004036994673563+0j), (0.017769676412990137+0j), (0.017511903214635888+0j), (0.01698297185985849+0j), (0.016586466424622227+0j), (0.015319273195561308+0j), (0.015079595045019482+0j), (0.014990676718189884+0j), (0.013757581548379938+0j), (0.013676069318126465+0j), (0.013112677925694661+0j), (0.012599794507987518+0j), (0.01189554902781907+0j), (0.011559309517848526+0j), (0.011282609963699588+0j), (0.010864829553061724+0j), (0.010363318233353106+0j), (0.010069230642517581+0j), (0.009645324089408288+0j), (0.009521914499517958+0j), (0.009423433941973562+0j), (0.009054033672473821+0j), (0.008464917086862983+0j), (0.008319215502940187+0j), (0.007985561228636326+0j), (0.007804642787663511+0j), (0.007347694633107736+0j), (0.007109568153967767+0j), (0.006827352578752909+0j), (0.0065625490979974175+0j), (0.006500349071654947+0j), (0.006105164259657322+0j), (0.006030658922482525+0j), (0.005835560657431792+0j), (0.005704203804683784+0j), (0.00533903048932974+0j), (0.005181621270981184+0j), (0.005049683601728831+0j), (0.004867598132886221+0j), (0.004686287131605647+0j), (0.004452501095604762+0j), (0.004267540614002572+0j), (0.0041170651781597956+0j), (0.0038972062000643477+0j), (0.0038579378368549517+0j), (0.0036189461996830813+0j), (0.003615357738781411+0j), (0.00343420264408072+0j), (0.00327873517005913+0j), (0.003011007193577094+0j), (0.0029746295947209625+0j), (0.002738372988465999+0j), (0.0026673657612424112+0j), (0.002514517789156234+0j), (0.002383424449829778+0j), (0.0023424214824520066+0j), (0.0022065348422303428+0j), (0.002124386400247651+0j), (0.002084490781193546+0j), (0.0019739325399970756+0j), (0.0018269618807473247+0j), (0.001814836229302788+0j), (0.0017653573470231539+0j), (0.0017267306158196484+0j), (0.001715558119803504+0j), (0.0015422382484940643+0j), (0.0014560073292393242+0j), (0.0013924494723496085+0j), (0.0012890000171994409+0j), (0.0012425019730282513+0j), (0.0011482709598404303+0j), (0.0011292210121724739+0j), (0.0011201496650002048+0j), (0.0010783487393371488+0j), (0.0010229602627735486+0j), (0.0010071970028978866+0j), (0.0009311891180563511+0j), (0.0009073102427731698+0j), (0.0008784749717534347+0j), (0.0008660319298745107+0j), (0.000770106371729882+0j), (0.0007380804891513327+0j), (0.0007230816539892928+0j), (0.000696518077179483+0j), (0.0006793971640798789+0j), (0.0006622610470945993+0j), (0.000638338029750627+0j), (0.0006163107117532637+0j), (0.0006085997448290768+0j), (0.0005764454179822944+0j), (0.0005574203764383786+0j), (0.0005277278441702894+0j), (0.000514256742670881+0j), (0.000498818056306779+0j), (0.0004876848193505973+0j), (0.00045884217749302966+0j), (0.0004359225109505715+0j), (0.00042690157525459454+0j), (0.00040399678594400904+0j), (0.0003905180404571029+0j), (0.00035524978404286294+0j), (0.0003529938952436072+0j), (0.00034513637029485593+0j), (0.0003290533343352638+0j), (0.0003139791294501393+0j), (0.00029309180030241276+0j), (0.00028651476795519203+0j), (0.00027837231657079175+0j), (0.0002675559862646069+0j), (0.0002625416650213381+0j), (0.00024723715513015+0j), (0.00024083320894855657+0j), (0.00023349418711369726+0j), (0.0002245421775882803+0j), (0.0002120959557526097+0j), (0.0002094158797567087+0j), (0.00019782952606830782+0j), (0.00019469596171487773+0j), (0.00018974009219323128+0j), (0.0001791021159621981+0j), (0.00017014087379137904+0j), (0.00016092278487822893+0j), (0.00015516901607918497+0j), (0.00014987375891932446+0j), (0.0001395409734739575+0j), (0.00013745831037614134+0j), (0.00013219403438774927+0j), (0.0001273327654128255+0j), (0.00011401011129964077+0j), (0.0001114719819518134+0j), (0.00010496167026512384+0j), (0.00010312378922829431+0j), (9.770875658041006e-05+0j), (9.320983443554859e-05+0j), (8.799178040197731e-05+0j), (8.308407523616035e-05+0j), (7.764686803279192e-05+0j), (7.108744397284572e-05+0j), (6.867545216405554e-05+0j), (6.474926778214613e-05+0j), (6.288556602900094e-05+0j), (5.826249427009473e-05+0j), (5.558766265984127e-05+0j), (4.764388834993194e-05+0j), (4.078231657405998e-05+0j), (3.817424583053048e-05+0j), (7.3737413116098e-14+0j), (7.221660640064588e-14+0j), (6.964656120968605e-14+0j), (6.697507550792052e-14+0j), (6.432268276666946e-14+0j), (6.370218027259742e-14+0j), (6.272792840116273e-14+0j), (6.193560007630516e-14+0j), (6.079660053134034e-14+0j), (5.899600677129658e-14+0j), (5.729611993809425e-14+0j), (5.452511490451539e-14+0j), (5.422160696343094e-14+0j), (5.3958234328314437e-14+0j), (5.2880855892561015e-14+0j), (5.238428704559999e-14+0j), (5.1201081479352856e-14+0j), (5.0645132226277774e-14+0j), (4.9733543212684416e-14+0j), (4.9004496674431094e-14+0j), (4.8708585889049646e-14+0j), (4.827426488281821e-14+0j), (4.793022359627439e-14+0j), (4.7251343139627085e-14+0j), (4.6619490143930996e-14+0j), (4.638206019368543e-14+0j), (4.606058375833447e-14+0j), (4.4859840038170696e-14+2.2445855234760624e-17j), (4.4859840038170696e-14-2.2445855234760624e-17j), (4.427064606981206e-14+0j), (4.39323033216473e-14+0j), (4.3432462664690945e-14+0j), (4.329576667044458e-14+0j), (4.271588289901122e-14+0j), (4.2353506553791283e-14+0j), (4.203417687484372e-14+0j), (4.167610992898029e-14+0j), (4.110169183330251e-14+0j), (4.0640928246701204e-14+0j), (4.0438293153298936e-14+0j), (4.0117877639674e-14+0j), (4.005480506126404e-14+0j), (3.9942631046870364e-14+0j), (3.887713054991202e-14+0j), (3.881298445826991e-14+0j), (3.8513140731598496e-14+0j), (3.824285240897439e-14+0j), (3.773811032268586e-14+0j), (3.750326375906475e-14+0j), (3.7085643445203823e-14+0j), (3.659459299464985e-14+0j), (3.6492876509447885e-14+0j), (3.628360006029126e-14+0j), (3.5688342702542665e-14+0j), (3.563589153841474e-14+0j), (3.5321369393415524e-14+0j), (3.482572358418552e-14+0j), (3.466274231072156e-14+0j), (3.438702308546008e-14+0j), (3.4145715094062544e-14+0j), (3.359832950928723e-14+0j), (3.3510496400463686e-14+0j), (3.3107085637857944e-14+0j), (3.296079064179828e-14+0j), (3.2584659325788667e-14+0j), (3.2498511261064464e-14+0j), (3.2243724329823e-14+0j), (3.2041894843825396e-14+0j), (3.1801371526938524e-14+0j), (3.146917005771917e-14+0j), (3.118521030603475e-14+0j), (3.0713039906036106e-14+0j), (3.0631686485075276e-14+0j), (3.0247456700099804e-14+0j), (3.005624612285027e-14+0j), (2.9861099558025547e-14+0j), (2.953565306244097e-14+0j), (2.9250086851000475e-14+0j), (2.9173462808543854e-14+0j), (2.9018620716157245e-14+0j), (2.876435025900889e-14+0j), (2.845344289610356e-14+0j), (2.8150268851921737e-14+0j), (2.778834782970987e-14+0j), (2.7555383987636085e-14+0j), (2.724177354452888e-14+0j), (2.7012869340659432e-14+0j), (2.696725669206223e-14+0j), (2.6618906933105484e-14+0j), (2.651815253159197e-14+0j), (2.620885210769027e-14+0j), (2.605013799265641e-14+0j), (2.570899985054444e-14+0j), (2.5408424797653876e-14+0j), (2.532476538501674e-14+0j), (2.501668670805727e-14+0j), (2.492888486093326e-14+0j), (2.4595905571070056e-14+0j), (2.4428439909532705e-14+0j), (2.4245212477399957e-14+0j), (2.3899048588753408e-14+0j), (2.3520897460962584e-14+0j), (2.3383946864637757e-14+0j), (2.2968876569395027e-14+0j), (2.2924665703933217e-14+0j), (2.2732456972581487e-14+0j), (2.2322369940652917e-14+0j), (2.213668026614971e-14+0j), (2.189808533930836e-14+4.3789163141067336e-17j), (2.189808533930836e-14-4.3789163141067336e-17j), (2.1674433358558973e-14+0j), (2.1517101075132745e-14+0j), (2.112618234779016e-14+0j), (2.060993115110199e-14+0j), (2.0477781607596573e-14+0j), (2.028742717919269e-14+0j), (1.9981545251388075e-14+0j), (1.9890719827115696e-14+0j), (1.955775792355988e-14+0j), (1.918916531653558e-14+0j), (1.9024844440286523e-14+0j), (1.8763849498115198e-14+0j), (1.8040342756618762e-14+0j), (1.7795770851464864e-14+0j), (1.763021192106329e-14+0j), (1.7082874617347444e-14+0j), (1.653883585344917e-14+0j), (1.5990560952429542e-14+0j), (1.50320628108898e-14+0j), (1.4619584882822734e-14+0j)]\n",
            "[ 24.9425684 +0.00000000e+00j  34.59426467+0.00000000e+00j\n",
            "  42.16680335+0.00000000e+00j  47.70626357+0.00000000e+00j\n",
            "  52.50648869+0.00000000e+00j  57.10320902+0.00000000e+00j\n",
            "  60.89005196+0.00000000e+00j  64.20161781+0.00000000e+00j\n",
            "  66.90045688+0.00000000e+00j  69.30831813+0.00000000e+00j\n",
            "  71.37564664+0.00000000e+00j  73.08237553+0.00000000e+00j\n",
            "  74.70702997+0.00000000e+00j  76.28846801+0.00000000e+00j\n",
            "  77.82959156+0.00000000e+00j  79.24930183+0.00000000e+00j\n",
            "  80.59570323+0.00000000e+00j  81.64119809+0.00000000e+00j\n",
            "  82.55593857+0.00000000e+00j  83.43952326+0.00000000e+00j\n",
            "  84.26130031+0.00000000e+00j  85.04589122+0.00000000e+00j\n",
            "  85.78121758+0.00000000e+00j  86.48040489+0.00000000e+00j\n",
            "  87.14023255+0.00000000e+00j  87.78573905+0.00000000e+00j\n",
            "  88.35828167+0.00000000e+00j  88.92166987+0.00000000e+00j\n",
            "  89.44528176+0.00000000e+00j  89.91585687+0.00000000e+00j\n",
            "  90.34355687+0.00000000e+00j  90.76286369+0.00000000e+00j\n",
            "  91.16525666+0.00000000e+00j  91.54057445+0.00000000e+00j\n",
            "  91.88651955+0.00000000e+00j  92.20279556+0.00000000e+00j\n",
            "  92.51545107+0.00000000e+00j  92.82263959+0.00000000e+00j\n",
            "  93.11830017+0.00000000e+00j  93.39035436+0.00000000e+00j\n",
            "  93.65495917+0.00000000e+00j  93.91533405+0.00000000e+00j\n",
            "  94.16909414+0.00000000e+00j  94.40267238+0.00000000e+00j\n",
            "  94.60602501+0.00000000e+00j  94.80579275+0.00000000e+00j\n",
            "  94.99522284+0.00000000e+00j  95.17111599+0.00000000e+00j\n",
            "  95.34517691+0.00000000e+00j  95.51541079+0.00000000e+00j\n",
            "  95.67671847+0.00000000e+00j  95.82994631+0.00000000e+00j\n",
            "  95.97972441+0.00000000e+00j  96.12520164+0.00000000e+00j\n",
            "  96.26261061+0.00000000e+00j  96.39373655+0.00000000e+00j\n",
            "  96.5193451 +0.00000000e+00j  96.64071577+0.00000000e+00j\n",
            "  96.75900853+0.00000000e+00j  96.87203357+0.00000000e+00j\n",
            "  96.97682934+0.00000000e+00j  97.07828823+0.00000000e+00j\n",
            "  97.17589823+0.00000000e+00j  97.27082791+0.00000000e+00j\n",
            "  97.3594238 +0.00000000e+00j  97.44548656+0.00000000e+00j\n",
            "  97.52919528+0.00000000e+00j  97.61012403+0.00000000e+00j\n",
            "  97.68873541+0.00000000e+00j  97.7645548 +0.00000000e+00j\n",
            "  97.83899833+0.00000000e+00j  97.91257584+0.00000000e+00j\n",
            "  97.98255704+0.00000000e+00j  98.04824786+0.00000000e+00j\n",
            "  98.11308141+0.00000000e+00j  98.17590174+0.00000000e+00j\n",
            "  98.23681739+0.00000000e+00j  98.2937303 +0.00000000e+00j\n",
            "  98.34922798+0.00000000e+00j  98.40271954+0.00000000e+00j\n",
            "  98.45520128+0.00000000e+00j  98.50629276+0.00000000e+00j\n",
            "  98.55512913+0.00000000e+00j  98.60225331+0.00000000e+00j\n",
            "  98.64889242+0.00000000e+00j  98.69433301+0.00000000e+00j\n",
            "  98.7358241 +0.00000000e+00j  98.77652044+0.00000000e+00j\n",
            "  98.81682717+0.00000000e+00j  98.85652846+0.00000000e+00j\n",
            "  98.89549438+0.00000000e+00j  98.93238805+0.00000000e+00j\n",
            "  98.96888337+0.00000000e+00j  99.00397736+0.00000000e+00j\n",
            "  99.03862324+0.00000000e+00j  99.07178022+0.00000000e+00j\n",
            "  99.10292501+0.00000000e+00j  99.13381404+0.00000000e+00j\n",
            "  99.16384255+0.00000000e+00j  99.19222695+0.00000000e+00j\n",
            "  99.22005081+0.00000000e+00j  99.24629619+0.00000000e+00j\n",
            "  99.27191234+0.00000000e+00j  99.2965279 +0.00000000e+00j\n",
            "  99.32074881+0.00000000e+00j  99.34405212+0.00000000e+00j\n",
            "  99.36680421+0.00000000e+00j  99.38850269+0.00000000e+00j\n",
            "  99.40979014+0.00000000e+00j  99.43018548+0.00000000e+00j\n",
            "  99.45015633+0.00000000e+00j  99.46974037+0.00000000e+00j\n",
            "  99.4886083 +0.00000000e+00j  99.50661234+0.00000000e+00j\n",
            "  99.52438201+0.00000000e+00j  99.54189392+0.00000000e+00j\n",
            "  99.55887689+0.00000000e+00j  99.57546336+0.00000000e+00j\n",
            "  99.59078263+0.00000000e+00j  99.60586222+0.00000000e+00j\n",
            "  99.6208529 +0.00000000e+00j  99.63461048+0.00000000e+00j\n",
            "  99.64828655+0.00000000e+00j  99.66139923+0.00000000e+00j\n",
            "  99.67399902+0.00000000e+00j  99.68589457+0.00000000e+00j\n",
            "  99.69745388+0.00000000e+00j  99.70873649+0.00000000e+00j\n",
            "  99.71960132+0.00000000e+00j  99.72996464+0.00000000e+00j\n",
            "  99.74003387+0.00000000e+00j  99.7496792 +0.00000000e+00j\n",
            "  99.75920111+0.00000000e+00j  99.76862454+0.00000000e+00j\n",
            "  99.77767858+0.00000000e+00j  99.78614349+0.00000000e+00j\n",
            "  99.79446271+0.00000000e+00j  99.80244827+0.00000000e+00j\n",
            "  99.81025291+0.00000000e+00j  99.81760061+0.00000000e+00j\n",
            "  99.82471018+0.00000000e+00j  99.83153753+0.00000000e+00j\n",
            "  99.83810008+0.00000000e+00j  99.84460043+0.00000000e+00j\n",
            "  99.85070559+0.00000000e+00j  99.85673625+0.00000000e+00j\n",
            "  99.86257181+0.00000000e+00j  99.86827602+0.00000000e+00j\n",
            "  99.87361505+0.00000000e+00j  99.87879667+0.00000000e+00j\n",
            "  99.88384635+0.00000000e+00j  99.88871395+0.00000000e+00j\n",
            "  99.89340024+0.00000000e+00j  99.89785274+0.00000000e+00j\n",
            "  99.90212028+0.00000000e+00j  99.90623734+0.00000000e+00j\n",
            "  99.91013455+0.00000000e+00j  99.91399249+0.00000000e+00j\n",
            "  99.91761143+0.00000000e+00j  99.92122679+0.00000000e+00j\n",
            "  99.92466099+0.00000000e+00j  99.92793973+0.00000000e+00j\n",
            "  99.93095074+0.00000000e+00j  99.93392537+0.00000000e+00j\n",
            "  99.93666374+0.00000000e+00j  99.9393311 +0.00000000e+00j\n",
            "  99.94184562+0.00000000e+00j  99.94422905+0.00000000e+00j\n",
            "  99.94657147+0.00000000e+00j  99.948778  +0.00000000e+00j\n",
            "  99.95090239+0.00000000e+00j  99.95298688+0.00000000e+00j\n",
            "  99.95496081+0.00000000e+00j  99.95678777+0.00000000e+00j\n",
            "  99.95860261+0.00000000e+00j  99.96036797+0.00000000e+00j\n",
            "  99.9620947 +0.00000000e+00j  99.96381026+0.00000000e+00j\n",
            "  99.96535249+0.00000000e+00j  99.9668085 +0.00000000e+00j\n",
            "  99.96820095+0.00000000e+00j  99.96948995+0.00000000e+00j\n",
            "  99.97073245+0.00000000e+00j  99.97188072+0.00000000e+00j\n",
            "  99.97300995+0.00000000e+00j  99.9741301 +0.00000000e+00j\n",
            "  99.97520844+0.00000000e+00j  99.9762314 +0.00000000e+00j\n",
            "  99.9772386 +0.00000000e+00j  99.97816979+0.00000000e+00j\n",
            "  99.9790771 +0.00000000e+00j  99.97995558+0.00000000e+00j\n",
            "  99.98082161+0.00000000e+00j  99.98159171+0.00000000e+00j\n",
            "  99.98232979+0.00000000e+00j  99.98305288+0.00000000e+00j\n",
            "  99.98374939+0.00000000e+00j  99.98442879+0.00000000e+00j\n",
            "  99.98509105+0.00000000e+00j  99.98572939+0.00000000e+00j\n",
            "  99.9863457 +0.00000000e+00j  99.9869543 +0.00000000e+00j\n",
            "  99.98753075+0.00000000e+00j  99.98808817+0.00000000e+00j\n",
            "  99.98861589+0.00000000e+00j  99.98913015+0.00000000e+00j\n",
            "  99.98962897+0.00000000e+00j  99.99011665+0.00000000e+00j\n",
            "  99.9905755 +0.00000000e+00j  99.99101142+0.00000000e+00j\n",
            "  99.99143832+0.00000000e+00j  99.99184232+0.00000000e+00j\n",
            "  99.99223283+0.00000000e+00j  99.99258808+0.00000000e+00j\n",
            "  99.99294108+0.00000000e+00j  99.99328622+0.00000000e+00j\n",
            "  99.99361527+0.00000000e+00j  99.99392925+0.00000000e+00j\n",
            "  99.99422234+0.00000000e+00j  99.99450885+0.00000000e+00j\n",
            "  99.99478723+0.00000000e+00j  99.99505478+0.00000000e+00j\n",
            "  99.99531732+0.00000000e+00j  99.99556456+0.00000000e+00j\n",
            "  99.99580539+0.00000000e+00j  99.99603889+0.00000000e+00j\n",
            "  99.99626343+0.00000000e+00j  99.99647553+0.00000000e+00j\n",
            "  99.99668494+0.00000000e+00j  99.99688277+0.00000000e+00j\n",
            "  99.99707747+0.00000000e+00j  99.99726721+0.00000000e+00j\n",
            "  99.99744631+0.00000000e+00j  99.99761645+0.00000000e+00j\n",
            "  99.99777737+0.00000000e+00j  99.99793254+0.00000000e+00j\n",
            "  99.99808242+0.00000000e+00j  99.99822196+0.00000000e+00j\n",
            "  99.99835942+0.00000000e+00j  99.99849161+0.00000000e+00j\n",
            "  99.99861894+0.00000000e+00j  99.99873295+0.00000000e+00j\n",
            "  99.99884442+0.00000000e+00j  99.99894939+0.00000000e+00j\n",
            "  99.99905251+0.00000000e+00j  99.99915022+0.00000000e+00j\n",
            "  99.99924343+0.00000000e+00j  99.99933142+0.00000000e+00j\n",
            "  99.9994145 +0.00000000e+00j  99.99949215+0.00000000e+00j\n",
            "  99.99956324+0.00000000e+00j  99.99963191+0.00000000e+00j\n",
            "  99.99969666+0.00000000e+00j  99.99975955+0.00000000e+00j\n",
            "  99.99981781+0.00000000e+00j  99.9998734 +0.00000000e+00j\n",
            "  99.99992104+0.00000000e+00j  99.99996183+0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +2.24458552e-17j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +4.37891631e-17j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j 100.        +0.00000000e+00j\n",
            " 100.        +0.00000000e+00j]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/transforms.py:789: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  points = np.array(args, dtype=float).reshape(2, 2)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py:1317: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  return np.asarray(x, float)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/transforms.py:789: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  points = np.array(args, dtype=float).reshape(2, 2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_explained_variance(sc.fit_transform(xTrain))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "MPLwqfGBgETB"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components= 150)\n",
        "xTrain_reduced = pca.fit(xTrain).transform(xTrain)\n",
        "xTest_reduced = pca.fit(xTest).transform(xTest)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(random_state=0).fit(xTrain_reduced, yTrain)\n",
        "pred = clf.predict(xTest_reduced)\n",
        "print(classification_report(yTest, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbj1mXnwMzoS",
        "outputId": "1a4b990d-c2b6-4e7d-a29f-b5510f05f727"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.94      0.99      0.97    106268\n",
            "         1.0       0.80      0.32      0.46      9118\n",
            "\n",
            "    accuracy                           0.94    115386\n",
            "   macro avg       0.87      0.66      0.71    115386\n",
            "weighted avg       0.93      0.94      0.93    115386\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LDA"
      ],
      "metadata": {
        "id": "PfyxC7JDNzq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LDA()\n",
        "xTrain_lda = lda.fit(xTrain, yTrain).transform(xTrain)\n",
        "xTest_lda = lda.transform(xTest)\n"
      ],
      "metadata": {
        "id": "1j442O1FMzrb"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(random_state=0).fit(xTrain_lda, yTrain)\n",
        "pred = clf.predict(xTest_lda)\n",
        "print(classification_report(yTest, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaNESb5IMzuM",
        "outputId": "df22c940-f9d0-41a2-a023-09fc2f397526"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.99      0.97    106268\n",
            "         1.0       0.79      0.35      0.48      9118\n",
            "\n",
            "    accuracy                           0.94    115386\n",
            "   macro avg       0.87      0.67      0.73    115386\n",
            "weighted avg       0.93      0.94      0.93    115386\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**observation**\n",
        "\n",
        "From classification report, we can find that PCA is better than LDA"
      ],
      "metadata": {
        "id": "2XcHZHt9Pad6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KZMAthuIMz-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bE1Jo3ZZc4i"
      },
      "source": [
        "# Task 2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTQvatGWZetZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw75y4TFZiFP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36wQ9XfkZiHz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBcPBWkwZiKg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yad_2wImZiNZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBBLdAU_ZiP1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqPx5zR_ZiSH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgrwanHDZiU5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZCCCeNMZiYb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6MVRhCmZibR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiAVEGL4Zidn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mb5g5J6rZigC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRN9vsJiZiiQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOpTZhVpZik5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARB8ky03Zind"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi-iIswXZiqi"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "AML_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}